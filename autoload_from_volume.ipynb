{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e00c468-4c6b-45ce-b683-2de0b010f7b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"create volume if not exists csv_files\")\n",
    "#this will create volume in default catalog, schema/db example workspace(catalog)/default(schema/db)/csv_files(volume)\\\n",
    "\n",
    "#after creating volume now you can add file to this volume by following steps\n",
    "#NEw->add or upload data->upload files to a volume -> select file same window below select volume by selecting your catalog/schema or db/volume upload once upload done you can see the files volume.\n",
    "\n",
    "# to ensure run below code\n",
    "dbutils.fs.ls(\"/Volumes/workspace/default/csv_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cff9707c-76d6-4e8d-881f-1351d25cf5a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "df_elec = spark.read.csv(\"/Volumes/workspace/default/csv_files/*.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93acf789-3508-4ca8-8543-29259dbe3f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--taking count before merge \n",
    "select count(1) from tryout1.bronze.stg_Electric_Vehicle_Population_Data\n",
    "union all\n",
    "select count(1) from tryout1.silver.Electric_Vehicle_Population_Data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee69e6f-ddc6-4f6a-99e4-8dca08c47e4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clnd_col = [i.replace(\" \",\"_\").replace(\"-\",\"_\").replace(\"(\",\"\").replace(\")\",\"\") for i in df_elec.columns]\n",
    "df_elec = df_elec.toDF(*clnd_col)\n",
    "df_elec = df_elec.withColumn(\"Created_at\", current_timestamp() ).withColumn(\"Modified_at\", lit(None).cast(\"timestamp\"))\n",
    "df_elec.write.format(\"delta\").mode(\"append\").saveAsTable(\"tryout1.bronze.stg_Electric_Vehicle_Population_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d41f81c3-e0bd-4826-9f05-f4eb2c2eed1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "read_tbl_src = spark.read.table(\"tryout1.bronze.stg_Electric_Vehicle_Population_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6034658-2676-44e5-b589-3c74049b28d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#to test merge adding incremental data\n",
    "# incr_data = spark.sql(\"\"\"select concat(VIN_1_10, '1') as VIN_1_10, concat(County, 'tk') as County, concat(City, 'tk') as City, concat(State, 'tk') as State,Postal_Code, Model_Year, Make, Model, Electric_Vehicle_Type,Clean_Alternative_Fuel_Vehicle_CAFV_Eligibility, Electric_Range,Base_MSRP,Legislative_District,DOL_Vehicle_ID+1::int as DOL_Vehicle_ID,Vehicle_Location,Electric_Utility,2020_Census_Tract,now() as Created_at, null as Modified_at from tryout1.bronze.stg_Electric_Vehicle_Population_Data where DOL_Vehicle_ID in (347724772,272165288,203182584) limit 3\"\"\")\n",
    "\n",
    "# read_tbl_src = read_tbl_src.union(incr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c0ebc22-0ded-4fd5-9d1f-aef34753071d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"tryout1.silver.Electric_Vehicle_Population_Data\"\n",
    "\n",
    "src_cols = set(read_tbl_src.columns)\n",
    "update_expr = {col:f\"src.{col}\" for col in list(src_cols) if col not in [\"Created_at\",\"Modified_at\"]}\n",
    "insert_expr = {col:f\"src.{col}\" for col in list(src_cols)}\n",
    "update_expr[\"Modified_at\"]= \"current_timestamp()\"\n",
    "\n",
    "merge_condition = f\"{' OR '.join([f'src.{col} != tgt.{col}' for col in src_cols if col not in ['Created_at', 'Modified_at']])}\"\n",
    "print(merge_condition)\n",
    "\n",
    "if not spark.catalog.tableExists(table_name):\n",
    "    read_tbl_src.write.format(\"delta\").mode(\"append\").saveAsTable(table_name)\n",
    "elif spark.catalog.tableExists(table_name):\n",
    "    tgt_cols = set(read_tbl_src.columns)\n",
    "    if src_cols != tgt_cols:\n",
    "        print(f\"Column mismatch: source={src_cols}, target={tgt_cols}\")\n",
    "        (\n",
    "        read_tbl_src.alias(\"src\")\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"append\")\n",
    "        .option(\"mergeSchema\", \"true\")\n",
    "        .saveAsTable(table_name)\n",
    "        )\n",
    "    target_data = DeltaTable.forName(spark,table_name)\n",
    "    target_data.alias(\"tgt\").merge(\n",
    "        read_tbl_src.alias(\"src\"),\"src.DOL_Vehicle_ID = tgt.DOL_Vehicle_ID\"\n",
    "        ).whenMatchedUpdate(\n",
    "            condition=merge_condition,\n",
    "            set=update_expr\n",
    "            ).whenNotMatchedInsert(values=insert_expr).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc1af8f-a52f-48c8-9faf-16e1527a05a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--taking count after merge \n",
    "select count(1) from tryout1.bronze.stg_Electric_Vehicle_Population_Data\n",
    "union all\n",
    "select count(1) from tryout1.silver.Electric_Vehicle_Population_Data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc8ea4f-7e83-4c64-bdc1-4a4914d443e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- drop table if exists tryout1.silver.Electric_Vehicle_Population_Data;\n",
    "-- drop table if exists tryout1.bronze.stg_Electric_Vehicle_Population_Data;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "autoload_from_volume",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
